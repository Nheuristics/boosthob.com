{"ast":null,"code":"import _toConsumableArray from \"/home/ayaz/Projects/boosthub.com/front_bone/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/toConsumableArray\";\nimport _possibleConstructorReturn from \"/home/ayaz/Projects/boosthub.com/front_bone/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/possibleConstructorReturn\";\nimport _getPrototypeOf from \"/home/ayaz/Projects/boosthub.com/front_bone/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/getPrototypeOf\";\nimport _inherits from \"/home/ayaz/Projects/boosthub.com/front_bone/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/inherits\";\nimport _classCallCheck from \"/home/ayaz/Projects/boosthub.com/front_bone/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/classCallCheck\";\nimport _createClass from \"/home/ayaz/Projects/boosthub.com/front_bone/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/createClass\";\n\nfunction _createForOfIteratorHelper(o, allowArrayLike) { var it = typeof Symbol !== \"undefined\" && o[Symbol.iterator] || o[\"@@iterator\"]; if (!it) { if (Array.isArray(o) || (it = _unsupportedIterableToArray(o)) || allowArrayLike && o && typeof o.length === \"number\") { if (it) o = it; var i = 0; var F = function F() {}; return { s: F, n: function n() { if (i >= o.length) return { done: true }; return { done: false, value: o[i++] }; }, e: function e(_e) { throw _e; }, f: F }; } throw new TypeError(\"Invalid attempt to iterate non-iterable instance.\\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.\"); } var normalCompletion = true, didErr = false, err; return { s: function s() { it = it.call(o); }, n: function n() { var step = it.next(); normalCompletion = step.done; return step; }, e: function e(_e2) { didErr = true; err = _e2; }, f: function f() { try { if (!normalCompletion && it.return != null) it.return(); } finally { if (didErr) throw err; } } }; }\n\nfunction _unsupportedIterableToArray(o, minLen) { if (!o) return; if (typeof o === \"string\") return _arrayLikeToArray(o, minLen); var n = Object.prototype.toString.call(o).slice(8, -1); if (n === \"Object\" && o.constructor) n = o.constructor.name; if (n === \"Map\" || n === \"Set\") return Array.from(o); if (n === \"Arguments\" || /^(?:Ui|I)nt(?:8|16|32)(?:Clamped)?Array$/.test(n)) return _arrayLikeToArray(o, minLen); }\n\nfunction _arrayLikeToArray(arr, len) { if (len == null || len > arr.length) len = arr.length; for (var i = 0, arr2 = new Array(len); i < len; i++) { arr2[i] = arr[i]; } return arr2; }\n\nimport { Parser, NodeSet, NodeType, DefaultBufferLength, NodeProp, Tree, IterMode } from '@lezer/common'; /// A parse stack. These are used internally by the parser to track\n/// parsing progress. They also provide some properties and methods\n/// that external code such as a tokenizer can use to get information\n/// about the parse state.\n\nvar Stack = /*#__PURE__*/function () {\n  /// @internal\n  function Stack( /// The parse that this stack is part of @internal\n  p, /// Holds state, input pos, buffer index triplets for all but the\n  /// top state @internal\n  stack, /// The current parse state @internal\n  state, // The position at which the next reduce should take place. This\n  // can be less than `this.pos` when skipped expressions have been\n  // added to the stack (which should be moved outside of the next\n  // reduction)\n  /// @internal\n  reducePos, /// The input position up to which this stack has parsed.\n  pos, /// The dynamic score of the stack, including dynamic precedence\n  /// and error-recovery penalties\n  /// @internal\n  score, // The output buffer. Holds (type, start, end, size) quads\n  // representing nodes created by the parser, where `size` is\n  // amount of buffer array entries covered by this node.\n  /// @internal\n  buffer, // The base offset of the buffer. When stacks are split, the split\n  // instance shared the buffer history with its parent up to\n  // `bufferBase`, which is the absolute offset (including the\n  // offset of previous splits) into the buffer at which this stack\n  // starts writing.\n  /// @internal\n  bufferBase, /// @internal\n  curContext) {\n    var lookAhead = arguments.length > 9 && arguments[9] !== undefined ? arguments[9] : 0;\n    var // A parent stack from which this was split off, if any. This is\n    // set up so that it always points to a stack that has some\n    // additional buffer content, never to a stack with an equal\n    // `bufferBase`.\n    /// @internal\n    parent = arguments.length > 10 ? arguments[10] : undefined;\n\n    _classCallCheck(this, Stack);\n\n    this.p = p;\n    this.stack = stack;\n    this.state = state;\n    this.reducePos = reducePos;\n    this.pos = pos;\n    this.score = score;\n    this.buffer = buffer;\n    this.bufferBase = bufferBase;\n    this.curContext = curContext;\n    this.lookAhead = lookAhead;\n    this.parent = parent;\n  } /// @internal\n\n\n  _createClass(Stack, [{\n    key: \"toString\",\n    value: function toString() {\n      return \"[\".concat(this.stack.filter(function (_, i) {\n        return i % 3 == 0;\n      }).concat(this.state), \"]@\").concat(this.pos).concat(this.score ? \"!\" + this.score : \"\");\n    } // Start an empty stack\n    /// @internal\n\n  }, {\n    key: \"pushState\",\n    // Push a state onto the stack, tracking its start position as well\n    // as the buffer base at that point.\n    /// @internal\n    value: function pushState(state, start) {\n      this.stack.push(this.state, start, this.bufferBase + this.buffer.length);\n      this.state = state;\n    } // Apply a reduce action\n    /// @internal\n\n  }, {\n    key: \"reduce\",\n    value: function reduce(action) {\n      var depth = action >> 19\n      /* ReduceDepthShift */\n      ,\n          type = action & 65535\n      /* ValueMask */\n      ;\n      var parser = this.p.parser;\n      var dPrec = parser.dynamicPrecedence(type);\n      if (dPrec) this.score += dPrec;\n\n      if (depth == 0) {\n        this.pushState(parser.getGoto(this.state, type, true), this.reducePos); // Zero-depth reductions are a special caseâ€”they add stuff to\n        // the stack without popping anything off.\n\n        if (type < parser.minRepeatTerm) this.storeNode(type, this.reducePos, this.reducePos, 4, true);\n        this.reduceContext(type, this.reducePos);\n        return;\n      } // Find the base index into `this.stack`, content after which will\n      // be dropped. Note that with `StayFlag` reductions we need to\n      // consume two extra frames (the dummy parent node for the skipped\n      // expression and the state that we'll be staying in, which should\n      // be moved to `this.state`).\n\n\n      var base = this.stack.length - (depth - 1) * 3 - (action & 262144\n      /* StayFlag */\n      ? 6 : 0);\n      var start = this.stack[base - 2];\n      var bufferBase = this.stack[base - 1],\n          count = this.bufferBase + this.buffer.length - bufferBase; // Store normal terms or `R -> R R` repeat reductions\n\n      if (type < parser.minRepeatTerm || action & 131072\n      /* RepeatFlag */\n      ) {\n        var pos = parser.stateFlag(this.state, 1\n        /* Skipped */\n        ) ? this.pos : this.reducePos;\n        this.storeNode(type, start, pos, count + 4, true);\n      }\n\n      if (action & 262144\n      /* StayFlag */\n      ) {\n        this.state = this.stack[base];\n      } else {\n        var baseStateID = this.stack[base - 3];\n        this.state = parser.getGoto(baseStateID, type, true);\n      }\n\n      while (this.stack.length > base) {\n        this.stack.pop();\n      }\n\n      this.reduceContext(type, start);\n    } // Shift a value into the buffer\n    /// @internal\n\n  }, {\n    key: \"storeNode\",\n    value: function storeNode(term, start, end) {\n      var size = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : 4;\n      var isReduce = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : false;\n\n      if (term == 0\n      /* Err */\n      && (!this.stack.length || this.stack[this.stack.length - 1] < this.buffer.length + this.bufferBase)) {\n        // Try to omit/merge adjacent error nodes\n        var cur = this,\n            top = this.buffer.length;\n\n        if (top == 0 && cur.parent) {\n          top = cur.bufferBase - cur.parent.bufferBase;\n          cur = cur.parent;\n        }\n\n        if (top > 0 && cur.buffer[top - 4] == 0\n        /* Err */\n        && cur.buffer[top - 1] > -1) {\n          if (start == end) return;\n\n          if (cur.buffer[top - 2] >= start) {\n            cur.buffer[top - 2] = end;\n            return;\n          }\n        }\n      }\n\n      if (!isReduce || this.pos == end) {\n        // Simple case, just append\n        this.buffer.push(term, start, end, size);\n      } else {\n        // There may be skipped nodes that have to be moved forward\n        var index = this.buffer.length;\n        if (index > 0 && this.buffer[index - 4] != 0\n        /* Err */\n        ) while (index > 0 && this.buffer[index - 2] > end) {\n          // Move this record forward\n          this.buffer[index] = this.buffer[index - 4];\n          this.buffer[index + 1] = this.buffer[index - 3];\n          this.buffer[index + 2] = this.buffer[index - 2];\n          this.buffer[index + 3] = this.buffer[index - 1];\n          index -= 4;\n          if (size > 4) size -= 4;\n        }\n        this.buffer[index] = term;\n        this.buffer[index + 1] = start;\n        this.buffer[index + 2] = end;\n        this.buffer[index + 3] = size;\n      }\n    } // Apply a shift action\n    /// @internal\n\n  }, {\n    key: \"shift\",\n    value: function shift(action, next, nextEnd) {\n      var start = this.pos;\n\n      if (action & 131072\n      /* GotoFlag */\n      ) {\n        this.pushState(action & 65535\n        /* ValueMask */\n        , this.pos);\n      } else if ((action & 262144\n      /* StayFlag */\n      ) == 0) {\n        // Regular shift\n        var nextState = action,\n            parser = this.p.parser;\n\n        if (nextEnd > this.pos || next <= parser.maxNode) {\n          this.pos = nextEnd;\n          if (!parser.stateFlag(nextState, 1\n          /* Skipped */\n          )) this.reducePos = nextEnd;\n        }\n\n        this.pushState(nextState, start);\n        this.shiftContext(next, start);\n        if (next <= parser.maxNode) this.buffer.push(next, start, nextEnd, 4);\n      } else {\n        // Shift-and-stay, which means this is a skipped token\n        this.pos = nextEnd;\n        this.shiftContext(next, start);\n        if (next <= this.p.parser.maxNode) this.buffer.push(next, start, nextEnd, 4);\n      }\n    } // Apply an action\n    /// @internal\n\n  }, {\n    key: \"apply\",\n    value: function apply(action, next, nextEnd) {\n      if (action & 65536\n      /* ReduceFlag */\n      ) this.reduce(action);else this.shift(action, next, nextEnd);\n    } // Add a prebuilt (reused) node into the buffer.\n    /// @internal\n\n  }, {\n    key: \"useNode\",\n    value: function useNode(value, next) {\n      var index = this.p.reused.length - 1;\n\n      if (index < 0 || this.p.reused[index] != value) {\n        this.p.reused.push(value);\n        index++;\n      }\n\n      var start = this.pos;\n      this.reducePos = this.pos = start + value.length;\n      this.pushState(next, start);\n      this.buffer.push(index, start, this.reducePos, -1\n      /* size == -1 means this is a reused value */\n      );\n      if (this.curContext) this.updateContext(this.curContext.tracker.reuse(this.curContext.context, value, this, this.p.stream.reset(this.pos - value.length)));\n    } // Split the stack. Due to the buffer sharing and the fact\n    // that `this.stack` tends to stay quite shallow, this isn't very\n    // expensive.\n    /// @internal\n\n  }, {\n    key: \"split\",\n    value: function split() {\n      var parent = this;\n      var off = parent.buffer.length; // Because the top of the buffer (after this.pos) may be mutated\n      // to reorder reductions and skipped tokens, and shared buffers\n      // should be immutable, this copies any outstanding skipped tokens\n      // to the new buffer, and puts the base pointer before them.\n\n      while (off > 0 && parent.buffer[off - 2] > parent.reducePos) {\n        off -= 4;\n      }\n\n      var buffer = parent.buffer.slice(off),\n          base = parent.bufferBase + off; // Make sure parent points to an actual parent with content, if there is such a parent.\n\n      while (parent && base == parent.bufferBase) {\n        parent = parent.parent;\n      }\n\n      return new Stack(this.p, this.stack.slice(), this.state, this.reducePos, this.pos, this.score, buffer, base, this.curContext, this.lookAhead, parent);\n    } // Try to recover from an error by 'deleting' (ignoring) one token.\n    /// @internal\n\n  }, {\n    key: \"recoverByDelete\",\n    value: function recoverByDelete(next, nextEnd) {\n      var isNode = next <= this.p.parser.maxNode;\n      if (isNode) this.storeNode(next, this.pos, nextEnd, 4);\n      this.storeNode(0\n      /* Err */\n      , this.pos, nextEnd, isNode ? 8 : 4);\n      this.pos = this.reducePos = nextEnd;\n      this.score -= 190\n      /* Delete */\n      ;\n    } /// Check if the given term would be able to be shifted (optionally\n    /// after some reductions) on this stack. This can be useful for\n    /// external tokenizers that want to make sure they only provide a\n    /// given token when it applies.\n\n  }, {\n    key: \"canShift\",\n    value: function canShift(term) {\n      for (var sim = new SimulatedStack(this);;) {\n        var action = this.p.parser.stateSlot(sim.state, 4\n        /* DefaultReduce */\n        ) || this.p.parser.hasAction(sim.state, term);\n        if ((action & 65536\n        /* ReduceFlag */\n        ) == 0) return true;\n        if (action == 0) return false;\n        sim.reduce(action);\n      }\n    } // Apply up to Recover.MaxNext recovery actions that conceptually\n    // inserts some missing token or rule.\n    /// @internal\n\n  }, {\n    key: \"recoverByInsert\",\n    value: function recoverByInsert(next) {\n      if (this.stack.length >= 300\n      /* MaxInsertStackDepth */\n      ) return [];\n      var nextStates = this.p.parser.nextStates(this.state);\n\n      if (nextStates.length > 4\n      /* MaxNext */\n      << 1 || this.stack.length >= 120\n      /* DampenInsertStackDepth */\n      ) {\n        var best = [];\n\n        for (var i = 0, s; i < nextStates.length; i += 2) {\n          if ((s = nextStates[i + 1]) != this.state && this.p.parser.hasAction(s, next)) best.push(nextStates[i], s);\n        }\n\n        if (this.stack.length < 120\n        /* DampenInsertStackDepth */\n        ) {\n          var _loop = function _loop(_i) {\n            var s = nextStates[_i + 1];\n            if (!best.some(function (v, i) {\n              return i & 1 && v == s;\n            })) best.push(nextStates[_i], s);\n          };\n\n          for (var _i = 0; best.length < 4\n          /* MaxNext */\n          << 1 && _i < nextStates.length; _i += 2) {\n            _loop(_i);\n          }\n        }\n\n        nextStates = best;\n      }\n\n      var result = [];\n\n      for (var _i2 = 0; _i2 < nextStates.length && result.length < 4\n      /* MaxNext */\n      ; _i2 += 2) {\n        var _s = nextStates[_i2 + 1];\n        if (_s == this.state) continue;\n        var stack = this.split();\n        stack.pushState(_s, this.pos);\n        stack.storeNode(0\n        /* Err */\n        , stack.pos, stack.pos, 4, true);\n        stack.shiftContext(nextStates[_i2], this.pos);\n        stack.score -= 200\n        /* Insert */\n        ;\n        result.push(stack);\n      }\n\n      return result;\n    } // Force a reduce, if possible. Return false if that can't\n    // be done.\n    /// @internal\n\n  }, {\n    key: \"forceReduce\",\n    value: function forceReduce() {\n      var reduce = this.p.parser.stateSlot(this.state, 5\n      /* ForcedReduce */\n      );\n      if ((reduce & 65536\n      /* ReduceFlag */\n      ) == 0) return false;\n      var parser = this.p.parser;\n\n      if (!parser.validAction(this.state, reduce)) {\n        var depth = reduce >> 19\n        /* ReduceDepthShift */\n        ,\n            term = reduce & 65535\n        /* ValueMask */\n        ;\n        var target = this.stack.length - depth * 3;\n        if (target < 0 || parser.getGoto(this.stack[target], term, false) < 0) return false;\n        this.storeNode(0\n        /* Err */\n        , this.reducePos, this.reducePos, 4, true);\n        this.score -= 100\n        /* Reduce */\n        ;\n      }\n\n      this.reducePos = this.pos;\n      this.reduce(reduce);\n      return true;\n    } /// @internal\n\n  }, {\n    key: \"forceAll\",\n    value: function forceAll() {\n      while (!this.p.parser.stateFlag(this.state, 2\n      /* Accepting */\n      )) {\n        if (!this.forceReduce()) {\n          this.storeNode(0\n          /* Err */\n          , this.pos, this.pos, 4, true);\n          break;\n        }\n      }\n\n      return this;\n    } /// Check whether this state has no further actions (assumed to be a direct descendant of the\n    /// top state, since any other states must be able to continue\n    /// somehow). @internal\n\n  }, {\n    key: \"restart\",\n    /// Restart the stack (put it back in its start state). Only safe\n    /// when this.stack.length == 3 (state is directly below the top\n    /// state). @internal\n    value: function restart() {\n      this.state = this.stack[0];\n      this.stack.length = 0;\n    } /// @internal\n\n  }, {\n    key: \"sameState\",\n    value: function sameState(other) {\n      if (this.state != other.state || this.stack.length != other.stack.length) return false;\n\n      for (var i = 0; i < this.stack.length; i += 3) {\n        if (this.stack[i] != other.stack[i]) return false;\n      }\n\n      return true;\n    } /// Get the parser used by this stack.\n\n  }, {\n    key: \"dialectEnabled\",\n    /// Test whether a given dialect (by numeric ID, as exported from\n    /// the terms file) is enabled.\n    value: function dialectEnabled(dialectID) {\n      return this.p.parser.dialect.flags[dialectID];\n    }\n  }, {\n    key: \"shiftContext\",\n    value: function shiftContext(term, start) {\n      if (this.curContext) this.updateContext(this.curContext.tracker.shift(this.curContext.context, term, this, this.p.stream.reset(start)));\n    }\n  }, {\n    key: \"reduceContext\",\n    value: function reduceContext(term, start) {\n      if (this.curContext) this.updateContext(this.curContext.tracker.reduce(this.curContext.context, term, this, this.p.stream.reset(start)));\n    } /// @internal\n\n  }, {\n    key: \"emitContext\",\n    value: function emitContext() {\n      var last = this.buffer.length - 1;\n      if (last < 0 || this.buffer[last] != -3) this.buffer.push(this.curContext.hash, this.reducePos, this.reducePos, -3);\n    } /// @internal\n\n  }, {\n    key: \"emitLookAhead\",\n    value: function emitLookAhead() {\n      var last = this.buffer.length - 1;\n      if (last < 0 || this.buffer[last] != -4) this.buffer.push(this.lookAhead, this.reducePos, this.reducePos, -4);\n    }\n  }, {\n    key: \"updateContext\",\n    value: function updateContext(context) {\n      if (context != this.curContext.context) {\n        var newCx = new StackContext(this.curContext.tracker, context);\n        if (newCx.hash != this.curContext.hash) this.emitContext();\n        this.curContext = newCx;\n      }\n    } /// @internal\n\n  }, {\n    key: \"setLookAhead\",\n    value: function setLookAhead(lookAhead) {\n      if (lookAhead > this.lookAhead) {\n        this.emitLookAhead();\n        this.lookAhead = lookAhead;\n      }\n    } /// @internal\n\n  }, {\n    key: \"close\",\n    value: function close() {\n      if (this.curContext && this.curContext.tracker.strict) this.emitContext();\n      if (this.lookAhead > 0) this.emitLookAhead();\n    }\n  }, {\n    key: \"context\",\n    /// The stack's current [context](#lr.ContextTracker) value, if\n    /// any. Its type will depend on the context tracker's type\n    /// parameter, or it will be `null` if there is no context\n    /// tracker.\n    get: function get() {\n      return this.curContext ? this.curContext.context : null;\n    }\n  }, {\n    key: \"deadEnd\",\n    get: function get() {\n      if (this.stack.length != 3) return false;\n      var parser = this.p.parser;\n      return parser.data[parser.stateSlot(this.state, 1\n      /* Actions */\n      )] == 65535\n      /* End */\n      && !parser.stateSlot(this.state, 4\n      /* DefaultReduce */\n      );\n    }\n  }, {\n    key: \"parser\",\n    get: function get() {\n      return this.p.parser;\n    }\n  }], [{\n    key: \"start\",\n    value: function start(p, state) {\n      var pos = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 0;\n      var cx = p.parser.context;\n      return new Stack(p, [], state, pos, pos, 0, [], 0, cx ? new StackContext(cx, cx.start) : null, 0, null);\n    }\n  }]);\n\n  return Stack;\n}();\n\nvar StackContext = function StackContext(tracker, context) {\n  _classCallCheck(this, StackContext);\n\n  this.tracker = tracker;\n  this.context = context;\n  this.hash = tracker.strict ? tracker.hash(context) : 0;\n};\n\nvar Recover;\n\n(function (Recover) {\n  Recover[Recover[\"Insert\"] = 200] = \"Insert\";\n  Recover[Recover[\"Delete\"] = 190] = \"Delete\";\n  Recover[Recover[\"Reduce\"] = 100] = \"Reduce\";\n  Recover[Recover[\"MaxNext\"] = 4] = \"MaxNext\";\n  Recover[Recover[\"MaxInsertStackDepth\"] = 300] = \"MaxInsertStackDepth\";\n  Recover[Recover[\"DampenInsertStackDepth\"] = 120] = \"DampenInsertStackDepth\";\n})(Recover || (Recover = {})); // Used to cheaply run some reductions to scan ahead without mutating\n// an entire stack\n\n\nvar SimulatedStack = /*#__PURE__*/function () {\n  function SimulatedStack(start) {\n    _classCallCheck(this, SimulatedStack);\n\n    this.start = start;\n    this.state = start.state;\n    this.stack = start.stack;\n    this.base = this.stack.length;\n  }\n\n  _createClass(SimulatedStack, [{\n    key: \"reduce\",\n    value: function reduce(action) {\n      var term = action & 65535\n      /* ValueMask */\n      ,\n          depth = action >> 19\n      /* ReduceDepthShift */\n      ;\n\n      if (depth == 0) {\n        if (this.stack == this.start.stack) this.stack = this.stack.slice();\n        this.stack.push(this.state, 0, 0);\n        this.base += 3;\n      } else {\n        this.base -= (depth - 1) * 3;\n      }\n\n      var goto = this.start.p.parser.getGoto(this.stack[this.base - 3], term, true);\n      this.state = goto;\n    }\n  }]);\n\n  return SimulatedStack;\n}(); // This is given to `Tree.build` to build a buffer, and encapsulates\n// the parent-stack-walking necessary to read the nodes.\n\n\nvar StackBufferCursor = /*#__PURE__*/function () {\n  function StackBufferCursor(stack, pos, index) {\n    _classCallCheck(this, StackBufferCursor);\n\n    this.stack = stack;\n    this.pos = pos;\n    this.index = index;\n    this.buffer = stack.buffer;\n    if (this.index == 0) this.maybeNext();\n  }\n\n  _createClass(StackBufferCursor, [{\n    key: \"maybeNext\",\n    value: function maybeNext() {\n      var next = this.stack.parent;\n\n      if (next != null) {\n        this.index = this.stack.bufferBase - next.bufferBase;\n        this.stack = next;\n        this.buffer = next.buffer;\n      }\n    }\n  }, {\n    key: \"next\",\n    value: function next() {\n      this.index -= 4;\n      this.pos -= 4;\n      if (this.index == 0) this.maybeNext();\n    }\n  }, {\n    key: \"fork\",\n    value: function fork() {\n      return new StackBufferCursor(this.stack, this.pos, this.index);\n    }\n  }, {\n    key: \"id\",\n    get: function get() {\n      return this.buffer[this.index - 4];\n    }\n  }, {\n    key: \"start\",\n    get: function get() {\n      return this.buffer[this.index - 3];\n    }\n  }, {\n    key: \"end\",\n    get: function get() {\n      return this.buffer[this.index - 2];\n    }\n  }, {\n    key: \"size\",\n    get: function get() {\n      return this.buffer[this.index - 1];\n    }\n  }], [{\n    key: \"create\",\n    value: function create(stack) {\n      var pos = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : stack.bufferBase + stack.buffer.length;\n      return new StackBufferCursor(stack, pos, pos - stack.bufferBase);\n    }\n  }]);\n\n  return StackBufferCursor;\n}();\n\nvar CachedToken = function CachedToken() {\n  _classCallCheck(this, CachedToken);\n\n  this.start = -1;\n  this.value = -1;\n  this.end = -1;\n  this.extended = -1;\n  this.lookAhead = 0;\n  this.mask = 0;\n  this.context = 0;\n};\n\nvar nullToken = new CachedToken(); /// [Tokenizers](#lr.ExternalTokenizer) interact with the input\n/// through this interface. It presents the input as a stream of\n/// characters, tracking lookahead and hiding the complexity of\n/// [ranges](#common.Parser.parse^ranges) from tokenizer code.\n\nvar InputStream = /*#__PURE__*/function () {\n  /// @internal\n  function InputStream( /// @internal\n  input, /// @internal\n  ranges) {\n    _classCallCheck(this, InputStream);\n\n    this.input = input;\n    this.ranges = ranges; /// @internal\n\n    this.chunk = \"\"; /// @internal\n\n    this.chunkOff = 0; /// Backup chunk\n\n    this.chunk2 = \"\";\n    this.chunk2Pos = 0; /// The character code of the next code unit in the input, or -1\n    /// when the stream is at the end of the input.\n\n    this.next = -1; /// @internal\n\n    this.token = nullToken;\n    this.rangeIndex = 0;\n    this.pos = this.chunkPos = ranges[0].from;\n    this.range = ranges[0];\n    this.end = ranges[ranges.length - 1].to;\n    this.readNext();\n  } /// @internal\n\n\n  _createClass(InputStream, [{\n    key: \"resolveOffset\",\n    value: function resolveOffset(offset, assoc) {\n      var range = this.range,\n          index = this.rangeIndex;\n      var pos = this.pos + offset;\n\n      while (pos < range.from) {\n        if (!index) return null;\n        var next = this.ranges[--index];\n        pos -= range.from - next.to;\n        range = next;\n      }\n\n      while (assoc < 0 ? pos > range.to : pos >= range.to) {\n        if (index == this.ranges.length - 1) return null;\n        var _next = this.ranges[++index];\n        pos += _next.from - range.to;\n        range = _next;\n      }\n\n      return pos;\n    } /// @internal\n\n  }, {\n    key: \"clipPos\",\n    value: function clipPos(pos) {\n      if (pos >= this.range.from && pos < this.range.to) return pos;\n\n      var _iterator = _createForOfIteratorHelper(this.ranges),\n          _step;\n\n      try {\n        for (_iterator.s(); !(_step = _iterator.n()).done;) {\n          var range = _step.value;\n          if (range.to > pos) return Math.max(pos, range.from);\n        }\n      } catch (err) {\n        _iterator.e(err);\n      } finally {\n        _iterator.f();\n      }\n\n      return this.end;\n    } /// Look at a code unit near the stream position. `.peek(0)` equals\n    /// `.next`, `.peek(-1)` gives you the previous character, and so\n    /// on.\n    ///\n    /// Note that looking around during tokenizing creates dependencies\n    /// on potentially far-away content, which may reduce the\n    /// effectiveness incremental parsingâ€”when looking forwardâ€”or even\n    /// cause invalid reparses when looking backward more than 25 code\n    /// units, since the library does not track lookbehind.\n\n  }, {\n    key: \"peek\",\n    value: function peek(offset) {\n      var idx = this.chunkOff + offset,\n          pos,\n          result;\n\n      if (idx >= 0 && idx < this.chunk.length) {\n        pos = this.pos + offset;\n        result = this.chunk.charCodeAt(idx);\n      } else {\n        var resolved = this.resolveOffset(offset, 1);\n        if (resolved == null) return -1;\n        pos = resolved;\n\n        if (pos >= this.chunk2Pos && pos < this.chunk2Pos + this.chunk2.length) {\n          result = this.chunk2.charCodeAt(pos - this.chunk2Pos);\n        } else {\n          var i = this.rangeIndex,\n              range = this.range;\n\n          while (range.to <= pos) {\n            range = this.ranges[++i];\n          }\n\n          this.chunk2 = this.input.chunk(this.chunk2Pos = pos);\n          if (pos + this.chunk2.length > range.to) this.chunk2 = this.chunk2.slice(0, range.to - pos);\n          result = this.chunk2.charCodeAt(0);\n        }\n      }\n\n      if (pos >= this.token.lookAhead) this.token.lookAhead = pos + 1;\n      return result;\n    } /// Accept a token. By default, the end of the token is set to the\n    /// current stream position, but you can pass an offset (relative to\n    /// the stream position) to change that.\n\n  }, {\n    key: \"acceptToken\",\n    value: function acceptToken(token) {\n      var endOffset = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 0;\n      var end = endOffset ? this.resolveOffset(endOffset, -1) : this.pos;\n      if (end == null || end < this.token.start) throw new RangeError(\"Token end out of bounds\");\n      this.token.value = token;\n      this.token.end = end;\n    }\n  }, {\n    key: \"getChunk\",\n    value: function getChunk() {\n      if (this.pos >= this.chunk2Pos && this.pos < this.chunk2Pos + this.chunk2.length) {\n        var chunk = this.chunk,\n            chunkPos = this.chunkPos;\n        this.chunk = this.chunk2;\n        this.chunkPos = this.chunk2Pos;\n        this.chunk2 = chunk;\n        this.chunk2Pos = chunkPos;\n        this.chunkOff = this.pos - this.chunkPos;\n      } else {\n        this.chunk2 = this.chunk;\n        this.chunk2Pos = this.chunkPos;\n        var nextChunk = this.input.chunk(this.pos);\n        var end = this.pos + nextChunk.length;\n        this.chunk = end > this.range.to ? nextChunk.slice(0, this.range.to - this.pos) : nextChunk;\n        this.chunkPos = this.pos;\n        this.chunkOff = 0;\n      }\n    }\n  }, {\n    key: \"readNext\",\n    value: function readNext() {\n      if (this.chunkOff >= this.chunk.length) {\n        this.getChunk();\n        if (this.chunkOff == this.chunk.length) return this.next = -1;\n      }\n\n      return this.next = this.chunk.charCodeAt(this.chunkOff);\n    } /// Move the stream forward N (defaults to 1) code units. Returns\n    /// the new value of [`next`](#lr.InputStream.next).\n\n  }, {\n    key: \"advance\",\n    value: function advance() {\n      var n = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : 1;\n      this.chunkOff += n;\n\n      while (this.pos + n >= this.range.to) {\n        if (this.rangeIndex == this.ranges.length - 1) return this.setDone();\n        n -= this.range.to - this.pos;\n        this.range = this.ranges[++this.rangeIndex];\n        this.pos = this.range.from;\n      }\n\n      this.pos += n;\n      if (this.pos >= this.token.lookAhead) this.token.lookAhead = this.pos + 1;\n      return this.readNext();\n    }\n  }, {\n    key: \"setDone\",\n    value: function setDone() {\n      this.pos = this.chunkPos = this.end;\n      this.range = this.ranges[this.rangeIndex = this.ranges.length - 1];\n      this.chunk = \"\";\n      return this.next = -1;\n    } /// @internal\n\n  }, {\n    key: \"reset\",\n    value: function reset(pos, token) {\n      if (token) {\n        this.token = token;\n        token.start = pos;\n        token.lookAhead = pos + 1;\n        token.value = token.extended = -1;\n      } else {\n        this.token = nullToken;\n      }\n\n      if (this.pos != pos) {\n        this.pos = pos;\n\n        if (pos == this.end) {\n          this.setDone();\n          return this;\n        }\n\n        while (pos < this.range.from) {\n          this.range = this.ranges[--this.rangeIndex];\n        }\n\n        while (pos >= this.range.to) {\n          this.range = this.ranges[++this.rangeIndex];\n        }\n\n        if (pos >= this.chunkPos && pos < this.chunkPos + this.chunk.length) {\n          this.chunkOff = pos - this.chunkPos;\n        } else {\n          this.chunk = \"\";\n          this.chunkOff = 0;\n        }\n\n        this.readNext();\n      }\n\n      return this;\n    } /// @internal\n\n  }, {\n    key: \"read\",\n    value: function read(from, to) {\n      if (from >= this.chunkPos && to <= this.chunkPos + this.chunk.length) return this.chunk.slice(from - this.chunkPos, to - this.chunkPos);\n      if (from >= this.chunk2Pos && to <= this.chunk2Pos + this.chunk2.length) return this.chunk2.slice(from - this.chunk2Pos, to - this.chunk2Pos);\n      if (from >= this.range.from && to <= this.range.to) return this.input.read(from, to);\n      var result = \"\";\n\n      var _iterator2 = _createForOfIteratorHelper(this.ranges),\n          _step2;\n\n      try {\n        for (_iterator2.s(); !(_step2 = _iterator2.n()).done;) {\n          var r = _step2.value;\n          if (r.from >= to) break;\n          if (r.to > from) result += this.input.read(Math.max(r.from, from), Math.min(r.to, to));\n        }\n      } catch (err) {\n        _iterator2.e(err);\n      } finally {\n        _iterator2.f();\n      }\n\n      return result;\n    }\n  }]);\n\n  return InputStream;\n}(); /// @internal\n\n\nvar TokenGroup = /*#__PURE__*/function () {\n  function TokenGroup(data, id) {\n    _classCallCheck(this, TokenGroup);\n\n    this.data = data;\n    this.id = id;\n  }\n\n  _createClass(TokenGroup, [{\n    key: \"token\",\n    value: function token(input, stack) {\n      readToken(this.data, input, stack, this.id);\n    }\n  }]);\n\n  return TokenGroup;\n}();\n\nTokenGroup.prototype.contextual = TokenGroup.prototype.fallback = TokenGroup.prototype.extend = false; /// `@external tokens` declarations in the grammar should resolve to\n/// an instance of this class.\n\nvar ExternalTokenizer = /// Create a tokenizer. The first argument is the function that,\n/// given an input stream, scans for the types of tokens it\n/// recognizes at the stream's position, and calls\n/// [`acceptToken`](#lr.InputStream.acceptToken) when it finds\n/// one.\nfunction ExternalTokenizer( /// @internal\ntoken) {\n  var options = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n\n  _classCallCheck(this, ExternalTokenizer);\n\n  this.token = token;\n  this.contextual = !!options.contextual;\n  this.fallback = !!options.fallback;\n  this.extend = !!options.extend;\n}; // Tokenizer data is stored a big uint16 array containing, for each\n// state:\n//\n//  - A group bitmask, indicating what token groups are reachable from\n//    this state, so that paths that can only lead to tokens not in\n//    any of the current groups can be cut off early.\n//\n//  - The position of the end of the state's sequence of accepting\n//    tokens\n//\n//  - The number of outgoing edges for the state\n//\n//  - The accepting tokens, as (token id, group mask) pairs\n//\n//  - The outgoing edges, as (start character, end character, state\n//    index) triples, with end character being exclusive\n//\n// This function interprets that data, running through a stream as\n// long as new states with the a matching group mask can be reached,\n// and updating `input.token` when it matches a token.\n\n\nfunction readToken(data, input, stack, group) {\n  var state = 0,\n      groupMask = 1 << group,\n      parser = stack.p.parser,\n      dialect = parser.dialect;\n\n  scan: for (;;) {\n    if ((groupMask & data[state]) == 0) break;\n    var accEnd = data[state + 1]; // Check whether this state can lead to a token in the current group\n    // Accept tokens in this state, possibly overwriting\n    // lower-precedence / shorter tokens\n\n    for (var i = state + 3; i < accEnd; i += 2) {\n      if ((data[i + 1] & groupMask) > 0) {\n        var term = data[i];\n\n        if (dialect.allows(term) && (input.token.value == -1 || input.token.value == term || parser.overrides(term, input.token.value))) {\n          input.acceptToken(term);\n          break;\n        }\n      }\n    }\n\n    var next = input.next,\n        low = 0,\n        high = data[state + 2]; // Special case for EOF\n\n    if (input.next < 0 && high > low && data[accEnd + high * 3 - 3] == 65535\n    /* End */\n    ) {\n      state = data[accEnd + high * 3 - 1];\n      continue scan;\n    } // Do a binary search on the state's edges\n\n\n    for (; low < high;) {\n      var mid = low + high >> 1;\n      var index = accEnd + mid + (mid << 1);\n      var from = data[index],\n          to = data[index + 1];\n      if (next < from) high = mid;else if (next >= to) low = mid + 1;else {\n        state = data[index + 2];\n        input.advance();\n        continue scan;\n      }\n    }\n\n    break;\n  }\n} // See lezer-generator/src/encode.ts for comments about the encoding\n// used here\n\n\nfunction decodeArray(input) {\n  var Type = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : Uint16Array;\n  if (typeof input != \"string\") return input;\n  var array = null;\n\n  for (var pos = 0, out = 0; pos < input.length;) {\n    var value = 0;\n\n    for (;;) {\n      var next = input.charCodeAt(pos++),\n          stop = false;\n\n      if (next == 126\n      /* BigValCode */\n      ) {\n        value = 65535\n        /* BigVal */\n        ;\n        break;\n      }\n\n      if (next >= 92\n      /* Gap2 */\n      ) next--;\n      if (next >= 34\n      /* Gap1 */\n      ) next--;\n      var digit = next - 32\n      /* Start */\n      ;\n\n      if (digit >= 46\n      /* Base */\n      ) {\n        digit -= 46\n        /* Base */\n        ;\n        stop = true;\n      }\n\n      value += digit;\n      if (stop) break;\n      value *= 46\n      /* Base */\n      ;\n    }\n\n    if (array) array[out++] = value;else array = new Type(value);\n  }\n\n  return array;\n} // Environment variable used to control console output\n\n\nvar verbose = typeof process != \"undefined\" && process.env && /\\bparse\\b/.test(process.env.LOG);\nvar stackIDs = null;\nvar Safety;\n\n(function (Safety) {\n  Safety[Safety[\"Margin\"] = 25] = \"Margin\";\n})(Safety || (Safety = {}));\n\nfunction cutAt(tree, pos, side) {\n  var cursor = tree.cursor(IterMode.IncludeAnonymous);\n  cursor.moveTo(pos);\n\n  for (;;) {\n    if (!(side < 0 ? cursor.childBefore(pos) : cursor.childAfter(pos))) for (;;) {\n      if ((side < 0 ? cursor.to < pos : cursor.from > pos) && !cursor.type.isError) return side < 0 ? Math.max(0, Math.min(cursor.to - 1, pos - 25\n      /* Margin */\n      )) : Math.min(tree.length, Math.max(cursor.from + 1, pos + 25\n      /* Margin */\n      ));\n      if (side < 0 ? cursor.prevSibling() : cursor.nextSibling()) break;\n      if (!cursor.parent()) return side < 0 ? 0 : tree.length;\n    }\n  }\n}\n\nvar FragmentCursor = /*#__PURE__*/function () {\n  function FragmentCursor(fragments, nodeSet) {\n    _classCallCheck(this, FragmentCursor);\n\n    this.fragments = fragments;\n    this.nodeSet = nodeSet;\n    this.i = 0;\n    this.fragment = null;\n    this.safeFrom = -1;\n    this.safeTo = -1;\n    this.trees = [];\n    this.start = [];\n    this.index = [];\n    this.nextFragment();\n  }\n\n  _createClass(FragmentCursor, [{\n    key: \"nextFragment\",\n    value: function nextFragment() {\n      var fr = this.fragment = this.i == this.fragments.length ? null : this.fragments[this.i++];\n\n      if (fr) {\n        this.safeFrom = fr.openStart ? cutAt(fr.tree, fr.from + fr.offset, 1) - fr.offset : fr.from;\n        this.safeTo = fr.openEnd ? cutAt(fr.tree, fr.to + fr.offset, -1) - fr.offset : fr.to;\n\n        while (this.trees.length) {\n          this.trees.pop();\n          this.start.pop();\n          this.index.pop();\n        }\n\n        this.trees.push(fr.tree);\n        this.start.push(-fr.offset);\n        this.index.push(0);\n        this.nextStart = this.safeFrom;\n      } else {\n        this.nextStart = 1e9;\n      }\n    } // `pos` must be >= any previously given `pos` for this cursor\n\n  }, {\n    key: \"nodeAt\",\n    value: function nodeAt(pos) {\n      if (pos < this.nextStart) return null;\n\n      while (this.fragment && this.safeTo <= pos) {\n        this.nextFragment();\n      }\n\n      if (!this.fragment) return null;\n\n      for (;;) {\n        var last = this.trees.length - 1;\n\n        if (last < 0) {\n          // End of tree\n          this.nextFragment();\n          return null;\n        }\n\n        var top = this.trees[last],\n            index = this.index[last];\n\n        if (index == top.children.length) {\n          this.trees.pop();\n          this.start.pop();\n          this.index.pop();\n          continue;\n        }\n\n        var next = top.children[index];\n        var start = this.start[last] + top.positions[index];\n\n        if (start > pos) {\n          this.nextStart = start;\n          return null;\n        }\n\n        if (next instanceof Tree) {\n          if (start == pos) {\n            if (start < this.safeFrom) return null;\n            var end = start + next.length;\n\n            if (end <= this.safeTo) {\n              var lookAhead = next.prop(NodeProp.lookAhead);\n              if (!lookAhead || end + lookAhead < this.fragment.to) return next;\n            }\n          }\n\n          this.index[last]++;\n\n          if (start + next.length >= Math.max(this.safeFrom, pos)) {\n            // Enter this node\n            this.trees.push(next);\n            this.start.push(start);\n            this.index.push(0);\n          }\n        } else {\n          this.index[last]++;\n          this.nextStart = start + next.length;\n        }\n      }\n    }\n  }]);\n\n  return FragmentCursor;\n}();\n\nvar TokenCache = /*#__PURE__*/function () {\n  function TokenCache(parser, stream) {\n    _classCallCheck(this, TokenCache);\n\n    this.stream = stream;\n    this.tokens = [];\n    this.mainToken = null;\n    this.actions = [];\n    this.tokens = parser.tokenizers.map(function (_) {\n      return new CachedToken();\n    });\n  }\n\n  _createClass(TokenCache, [{\n    key: \"getActions\",\n    value: function getActions(stack) {\n      var actionIndex = 0;\n      var main = null;\n      var parser = stack.p.parser,\n          tokenizers = parser.tokenizers;\n      var mask = parser.stateSlot(stack.state, 3\n      /* TokenizerMask */\n      );\n      var context = stack.curContext ? stack.curContext.hash : 0;\n      var lookAhead = 0;\n\n      for (var i = 0; i < tokenizers.length; i++) {\n        if ((1 << i & mask) == 0) continue;\n        var tokenizer = tokenizers[i],\n            token = this.tokens[i];\n        if (main && !tokenizer.fallback) continue;\n\n        if (tokenizer.contextual || token.start != stack.pos || token.mask != mask || token.context != context) {\n          this.updateCachedToken(token, tokenizer, stack);\n          token.mask = mask;\n          token.context = context;\n        }\n\n        if (token.lookAhead > token.end + 25\n        /* Margin */\n        ) lookAhead = Math.max(token.lookAhead, lookAhead);\n\n        if (token.value != 0\n        /* Err */\n        ) {\n          var startIndex = actionIndex;\n          if (token.extended > -1) actionIndex = this.addActions(stack, token.extended, token.end, actionIndex);\n          actionIndex = this.addActions(stack, token.value, token.end, actionIndex);\n\n          if (!tokenizer.extend) {\n            main = token;\n            if (actionIndex > startIndex) break;\n          }\n        }\n      }\n\n      while (this.actions.length > actionIndex) {\n        this.actions.pop();\n      }\n\n      if (lookAhead) stack.setLookAhead(lookAhead);\n\n      if (!main && stack.pos == this.stream.end) {\n        main = new CachedToken();\n        main.value = stack.p.parser.eofTerm;\n        main.start = main.end = stack.pos;\n        actionIndex = this.addActions(stack, main.value, main.end, actionIndex);\n      }\n\n      this.mainToken = main;\n      return this.actions;\n    }\n  }, {\n    key: \"getMainToken\",\n    value: function getMainToken(stack) {\n      if (this.mainToken) return this.mainToken;\n      var main = new CachedToken(),\n          pos = stack.pos,\n          p = stack.p;\n      main.start = pos;\n      main.end = Math.min(pos + 1, p.stream.end);\n      main.value = pos == p.stream.end ? p.parser.eofTerm : 0\n      /* Err */\n      ;\n      return main;\n    }\n  }, {\n    key: \"updateCachedToken\",\n    value: function updateCachedToken(token, tokenizer, stack) {\n      var start = this.stream.clipPos(stack.pos);\n      tokenizer.token(this.stream.reset(start, token), stack);\n\n      if (token.value > -1) {\n        var parser = stack.p.parser;\n\n        for (var i = 0; i < parser.specialized.length; i++) {\n          if (parser.specialized[i] == token.value) {\n            var result = parser.specializers[i](this.stream.read(token.start, token.end), stack);\n\n            if (result >= 0 && stack.p.parser.dialect.allows(result >> 1)) {\n              if ((result & 1) == 0\n              /* Specialize */\n              ) token.value = result >> 1;else token.extended = result >> 1;\n              break;\n            }\n          }\n        }\n      } else {\n        token.value = 0\n        /* Err */\n        ;\n        token.end = this.stream.clipPos(start + 1);\n      }\n    }\n  }, {\n    key: \"putAction\",\n    value: function putAction(action, token, end, index) {\n      // Don't add duplicate actions\n      for (var i = 0; i < index; i += 3) {\n        if (this.actions[i] == action) return index;\n      }\n\n      this.actions[index++] = action;\n      this.actions[index++] = token;\n      this.actions[index++] = end;\n      return index;\n    }\n  }, {\n    key: \"addActions\",\n    value: function addActions(stack, token, end, index) {\n      var state = stack.state,\n          parser = stack.p.parser,\n          data = parser.data;\n\n      for (var set = 0; set < 2; set++) {\n        for (var i = parser.stateSlot(state, set ? 2\n        /* Skip */\n        : 1\n        /* Actions */\n        );; i += 3) {\n          if (data[i] == 65535\n          /* End */\n          ) {\n            if (data[i + 1] == 1\n            /* Next */\n            ) {\n              i = pair(data, i + 2);\n            } else {\n              if (index == 0 && data[i + 1] == 2\n              /* Other */\n              ) index = this.putAction(pair(data, i + 2), token, end, index);\n              break;\n            }\n          }\n\n          if (data[i] == token) index = this.putAction(pair(data, i + 1), token, end, index);\n        }\n      }\n\n      return index;\n    }\n  }]);\n\n  return TokenCache;\n}();\n\nvar Rec;\n\n(function (Rec) {\n  Rec[Rec[\"Distance\"] = 5] = \"Distance\";\n  Rec[Rec[\"MaxRemainingPerStep\"] = 3] = \"MaxRemainingPerStep\"; // When two stacks have been running independently long enough to\n  // add this many elements to their buffers, prune one.\n\n  Rec[Rec[\"MinBufferLengthPrune\"] = 500] = \"MinBufferLengthPrune\";\n  Rec[Rec[\"ForceReduceLimit\"] = 10] = \"ForceReduceLimit\"; // Once a stack reaches this depth (in .stack.length) force-reduce\n  // it back to CutTo to avoid creating trees that overflow the stack\n  // on recursive traversal.\n\n  Rec[Rec[\"CutDepth\"] = 15000] = \"CutDepth\";\n  Rec[Rec[\"CutTo\"] = 9000] = \"CutTo\";\n})(Rec || (Rec = {}));\n\nvar Parse = /*#__PURE__*/function () {\n  function Parse(parser, input, fragments, ranges) {\n    _classCallCheck(this, Parse);\n\n    this.parser = parser;\n    this.input = input;\n    this.ranges = ranges;\n    this.recovering = 0;\n    this.nextStackID = 0x2654; // â™”, â™•, â™–, â™—, â™˜, â™™, â™ , â™¡, â™¢, â™£, â™¤, â™¥, â™¦, â™§\n\n    this.minStackPos = 0;\n    this.reused = [];\n    this.stoppedAt = null;\n    this.stream = new InputStream(input, ranges);\n    this.tokens = new TokenCache(parser, this.stream);\n    this.topTerm = parser.top[1];\n    var from = ranges[0].from;\n    this.stacks = [Stack.start(this, parser.top[0], from)];\n    this.fragments = fragments.length && this.stream.end - from > parser.bufferLength * 4 ? new FragmentCursor(fragments, parser.nodeSet) : null;\n  }\n\n  _createClass(Parse, [{\n    key: \"advance\",\n    // Move the parser forward. This will process all parse stacks at\n    // `this.pos` and try to advance them to a further position. If no\n    // stack for such a position is found, it'll start error-recovery.\n    //\n    // When the parse is finished, this will return a syntax tree. When\n    // not, it returns `null`.\n    value: function advance() {\n      var stacks = this.stacks,\n          pos = this.minStackPos; // This will hold stacks beyond `pos`.\n\n      var newStacks = this.stacks = [];\n      var stopped, stoppedTokens; // Keep advancing any stacks at `pos` until they either move\n      // forward or can't be advanced. Gather stacks that can't be\n      // advanced further in `stopped`.\n\n      for (var i = 0; i < stacks.length; i++) {\n        var _stack = stacks[i];\n\n        for (;;) {\n          this.tokens.mainToken = null;\n\n          if (_stack.pos > pos) {\n            newStacks.push(_stack);\n          } else if (this.advanceStack(_stack, newStacks, stacks)) {\n            continue;\n          } else {\n            if (!stopped) {\n              stopped = [];\n              stoppedTokens = [];\n            }\n\n            stopped.push(_stack);\n            var tok = this.tokens.getMainToken(_stack);\n            stoppedTokens.push(tok.value, tok.end);\n          }\n\n          break;\n        }\n      }\n\n      if (!newStacks.length) {\n        var finished = stopped && findFinished(stopped);\n        if (finished) return this.stackToTree(finished);\n\n        if (this.parser.strict) {\n          if (verbose && stopped) console.log(\"Stuck with token \" + (this.tokens.mainToken ? this.parser.getName(this.tokens.mainToken.value) : \"none\"));\n          throw new SyntaxError(\"No parse at \" + pos);\n        }\n\n        if (!this.recovering) this.recovering = 5\n        /* Distance */\n        ;\n      }\n\n      if (this.recovering && stopped) {\n        var _finished = this.stoppedAt != null && stopped[0].pos > this.stoppedAt ? stopped[0] : this.runRecovery(stopped, stoppedTokens, newStacks);\n\n        if (_finished) return this.stackToTree(_finished.forceAll());\n      }\n\n      if (this.recovering) {\n        var maxRemaining = this.recovering == 1 ? 1 : this.recovering * 3\n        /* MaxRemainingPerStep */\n        ;\n\n        if (newStacks.length > maxRemaining) {\n          newStacks.sort(function (a, b) {\n            return b.score - a.score;\n          });\n\n          while (newStacks.length > maxRemaining) {\n            newStacks.pop();\n          }\n        }\n\n        if (newStacks.some(function (s) {\n          return s.reducePos > pos;\n        })) this.recovering--;\n      } else if (newStacks.length > 1) {\n        // Prune stacks that are in the same state, or that have been\n        // running without splitting for a while, to avoid getting stuck\n        // with multiple successful stacks running endlessly on.\n        outer: for (var _i3 = 0; _i3 < newStacks.length - 1; _i3++) {\n          var _stack2 = newStacks[_i3];\n\n          for (var j = _i3 + 1; j < newStacks.length; j++) {\n            var other = newStacks[j];\n\n            if (_stack2.sameState(other) || _stack2.buffer.length > 500\n            /* MinBufferLengthPrune */\n            && other.buffer.length > 500\n            /* MinBufferLengthPrune */\n            ) {\n              if ((_stack2.score - other.score || _stack2.buffer.length - other.buffer.length) > 0) {\n                newStacks.splice(j--, 1);\n              } else {\n                newStacks.splice(_i3--, 1);\n                continue outer;\n              }\n            }\n          }\n        }\n      }\n\n      this.minStackPos = newStacks[0].pos;\n\n      for (var _i4 = 1; _i4 < newStacks.length; _i4++) {\n        if (newStacks[_i4].pos < this.minStackPos) this.minStackPos = newStacks[_i4].pos;\n      }\n\n      return null;\n    }\n  }, {\n    key: \"stopAt\",\n    value: function stopAt(pos) {\n      if (this.stoppedAt != null && this.stoppedAt < pos) throw new RangeError(\"Can't move stoppedAt forward\");\n      this.stoppedAt = pos;\n    } // Returns an updated version of the given stack, or null if the\n    // stack can't advance normally. When `split` and `stacks` are\n    // given, stacks split off by ambiguous operations will be pushed to\n    // `split`, or added to `stacks` if they move `pos` forward.\n\n  }, {\n    key: \"advanceStack\",\n    value: function advanceStack(stack, stacks, split) {\n      var start = stack.pos,\n          parser = this.parser;\n      var base = verbose ? this.stackID(stack) + \" -> \" : \"\";\n      if (this.stoppedAt != null && start > this.stoppedAt) return stack.forceReduce() ? stack : null;\n\n      if (this.fragments) {\n        var strictCx = stack.curContext && stack.curContext.tracker.strict,\n            cxHash = strictCx ? stack.curContext.hash : 0;\n\n        for (var cached = this.fragments.nodeAt(start); cached;) {\n          var match = this.parser.nodeSet.types[cached.type.id] == cached.type ? parser.getGoto(stack.state, cached.type.id) : -1;\n\n          if (match > -1 && cached.length && (!strictCx || (cached.prop(NodeProp.contextHash) || 0) == cxHash)) {\n            stack.useNode(cached, match);\n            if (verbose) console.log(base + this.stackID(stack) + \" (via reuse of \".concat(parser.getName(cached.type.id), \")\"));\n            return true;\n          }\n\n          if (!(cached instanceof Tree) || cached.children.length == 0 || cached.positions[0] > 0) break;\n          var inner = cached.children[0];\n          if (inner instanceof Tree && cached.positions[0] == 0) cached = inner;else break;\n        }\n      }\n\n      var defaultReduce = parser.stateSlot(stack.state, 4\n      /* DefaultReduce */\n      );\n\n      if (defaultReduce > 0) {\n        stack.reduce(defaultReduce);\n        if (verbose) console.log(base + this.stackID(stack) + \" (via always-reduce \".concat(parser.getName(defaultReduce & 65535\n        /* ValueMask */\n        ), \")\"));\n        return true;\n      }\n\n      if (stack.stack.length >= 15000\n      /* CutDepth */\n      ) {\n        while (stack.stack.length > 9000\n        /* CutTo */\n        && stack.forceReduce()) {}\n      }\n\n      var actions = this.tokens.getActions(stack);\n\n      for (var i = 0; i < actions.length;) {\n        var action = actions[i++],\n            term = actions[i++],\n            end = actions[i++];\n        var last = i == actions.length || !split;\n        var localStack = last ? stack : stack.split();\n        localStack.apply(action, term, end);\n        if (verbose) console.log(base + this.stackID(localStack) + \" (via \".concat((action & 65536\n        /* ReduceFlag */\n        ) == 0 ? \"shift\" : \"reduce of \".concat(parser.getName(action & 65535\n        /* ValueMask */\n        )), \" for \").concat(parser.getName(term), \" @ \").concat(start).concat(localStack == stack ? \"\" : \", split\", \")\"));\n        if (last) return true;else if (localStack.pos > start) stacks.push(localStack);else split.push(localStack);\n      }\n\n      return false;\n    } // Advance a given stack forward as far as it will go. Returns the\n    // (possibly updated) stack if it got stuck, or null if it moved\n    // forward and was given to `pushStackDedup`.\n\n  }, {\n    key: \"advanceFully\",\n    value: function advanceFully(stack, newStacks) {\n      var pos = stack.pos;\n\n      for (;;) {\n        if (!this.advanceStack(stack, null, null)) return false;\n\n        if (stack.pos > pos) {\n          pushStackDedup(stack, newStacks);\n          return true;\n        }\n      }\n    }\n  }, {\n    key: \"runRecovery\",\n    value: function runRecovery(stacks, tokens, newStacks) {\n      var finished = null,\n          restarted = false;\n\n      for (var i = 0; i < stacks.length; i++) {\n        var _stack3 = stacks[i],\n            token = tokens[i << 1],\n            tokenEnd = tokens[(i << 1) + 1];\n        var base = verbose ? this.stackID(_stack3) + \" -> \" : \"\";\n\n        if (_stack3.deadEnd) {\n          if (restarted) continue;\n          restarted = true;\n\n          _stack3.restart();\n\n          if (verbose) console.log(base + this.stackID(_stack3) + \" (restarted)\");\n          var done = this.advanceFully(_stack3, newStacks);\n          if (done) continue;\n        }\n\n        var force = _stack3.split(),\n            forceBase = base;\n\n        for (var j = 0; force.forceReduce() && j < 10\n        /* ForceReduceLimit */\n        ; j++) {\n          if (verbose) console.log(forceBase + this.stackID(force) + \" (via force-reduce)\");\n\n          var _done = this.advanceFully(force, newStacks);\n\n          if (_done) break;\n          if (verbose) forceBase = this.stackID(force) + \" -> \";\n        }\n\n        var _iterator3 = _createForOfIteratorHelper(_stack3.recoverByInsert(token)),\n            _step3;\n\n        try {\n          for (_iterator3.s(); !(_step3 = _iterator3.n()).done;) {\n            var insert = _step3.value;\n            if (verbose) console.log(base + this.stackID(insert) + \" (via recover-insert)\");\n            this.advanceFully(insert, newStacks);\n          }\n        } catch (err) {\n          _iterator3.e(err);\n        } finally {\n          _iterator3.f();\n        }\n\n        if (this.stream.end > _stack3.pos) {\n          if (tokenEnd == _stack3.pos) {\n            tokenEnd++;\n            token = 0\n            /* Err */\n            ;\n          }\n\n          _stack3.recoverByDelete(token, tokenEnd);\n\n          if (verbose) console.log(base + this.stackID(_stack3) + \" (via recover-delete \".concat(this.parser.getName(token), \")\"));\n          pushStackDedup(_stack3, newStacks);\n        } else if (!finished || finished.score < _stack3.score) {\n          finished = _stack3;\n        }\n      }\n\n      return finished;\n    } // Convert the stack's buffer to a syntax tree.\n\n  }, {\n    key: \"stackToTree\",\n    value: function stackToTree(stack) {\n      stack.close();\n      return Tree.build({\n        buffer: StackBufferCursor.create(stack),\n        nodeSet: this.parser.nodeSet,\n        topID: this.topTerm,\n        maxBufferLength: this.parser.bufferLength,\n        reused: this.reused,\n        start: this.ranges[0].from,\n        length: stack.pos - this.ranges[0].from,\n        minRepeatType: this.parser.minRepeatTerm\n      });\n    }\n  }, {\n    key: \"stackID\",\n    value: function stackID(stack) {\n      var id = (stackIDs || (stackIDs = new WeakMap())).get(stack);\n      if (!id) stackIDs.set(stack, id = String.fromCodePoint(this.nextStackID++));\n      return id + stack;\n    }\n  }, {\n    key: \"parsedPos\",\n    get: function get() {\n      return this.minStackPos;\n    }\n  }]);\n\n  return Parse;\n}();\n\nfunction pushStackDedup(stack, newStacks) {\n  for (var i = 0; i < newStacks.length; i++) {\n    var other = newStacks[i];\n\n    if (other.pos == stack.pos && other.sameState(stack)) {\n      if (newStacks[i].score < stack.score) newStacks[i] = stack;\n      return;\n    }\n  }\n\n  newStacks.push(stack);\n}\n\nvar Dialect = /*#__PURE__*/function () {\n  function Dialect(source, flags, disabled) {\n    _classCallCheck(this, Dialect);\n\n    this.source = source;\n    this.flags = flags;\n    this.disabled = disabled;\n  }\n\n  _createClass(Dialect, [{\n    key: \"allows\",\n    value: function allows(term) {\n      return !this.disabled || this.disabled[term] == 0;\n    }\n  }]);\n\n  return Dialect;\n}();\n\nvar id = function id(x) {\n  return x;\n}; /// Context trackers are used to track stateful context (such as\n/// indentation in the Python grammar, or parent elements in the XML\n/// grammar) needed by external tokenizers. You declare them in a\n/// grammar file as `@context exportName from \"module\"`.\n///\n/// Context values should be immutable, and can be updated (replaced)\n/// on shift or reduce actions.\n///\n/// The export used in a `@context` declaration should be of this\n/// type.\n\n\nvar ContextTracker = /// Define a context tracker.\nfunction ContextTracker(spec) {\n  _classCallCheck(this, ContextTracker);\n\n  this.start = spec.start;\n  this.shift = spec.shift || id;\n  this.reduce = spec.reduce || id;\n  this.reuse = spec.reuse || id;\n\n  this.hash = spec.hash || function () {\n    return 0;\n  };\n\n  this.strict = spec.strict !== false;\n}; /// Holds the parse tables for a given grammar, as generated by\n/// `lezer-generator`, and provides [methods](#common.Parser) to parse\n/// content with.\n\n\nvar LRParser = /*#__PURE__*/function (_Parser) {\n  _inherits(LRParser, _Parser);\n\n  /// @internal\n  function LRParser(spec) {\n    var _this$nodeSet;\n\n    var _this;\n\n    _classCallCheck(this, LRParser);\n\n    _this = _possibleConstructorReturn(this, _getPrototypeOf(LRParser).call(this)); /// @internal\n\n    _this.wrappers = [];\n    if (spec.version != 14\n    /* Version */\n    ) throw new RangeError(\"Parser version (\".concat(spec.version, \") doesn't match runtime version (\", 14\n    /* Version */\n    , \")\"));\n    var nodeNames = spec.nodeNames.split(\" \");\n    _this.minRepeatTerm = nodeNames.length;\n\n    for (var i = 0; i < spec.repeatNodeCount; i++) {\n      nodeNames.push(\"\");\n    }\n\n    var topTerms = Object.keys(spec.topRules).map(function (r) {\n      return spec.topRules[r][1];\n    });\n    var nodeProps = [];\n\n    for (var _i5 = 0; _i5 < nodeNames.length; _i5++) {\n      nodeProps.push([]);\n    }\n\n    function setProp(nodeID, prop, value) {\n      nodeProps[nodeID].push([prop, prop.deserialize(String(value))]);\n    }\n\n    if (spec.nodeProps) {\n      var _iterator4 = _createForOfIteratorHelper(spec.nodeProps),\n          _step4;\n\n      try {\n        for (_iterator4.s(); !(_step4 = _iterator4.n()).done;) {\n          var propSpec = _step4.value;\n          var prop = propSpec[0];\n          if (typeof prop == \"string\") prop = NodeProp[prop];\n\n          for (var _i6 = 1; _i6 < propSpec.length;) {\n            var next = propSpec[_i6++];\n\n            if (next >= 0) {\n              setProp(next, prop, propSpec[_i6++]);\n            } else {\n              var value = propSpec[_i6 + -next];\n\n              for (var j = -next; j > 0; j--) {\n                setProp(propSpec[_i6++], prop, value);\n              }\n\n              _i6++;\n            }\n          }\n        }\n      } catch (err) {\n        _iterator4.e(err);\n      } finally {\n        _iterator4.f();\n      }\n    }\n\n    _this.nodeSet = new NodeSet(nodeNames.map(function (name, i) {\n      return NodeType.define({\n        name: i >= _this.minRepeatTerm ? undefined : name,\n        id: i,\n        props: nodeProps[i],\n        top: topTerms.indexOf(i) > -1,\n        error: i == 0,\n        skipped: spec.skippedNodes && spec.skippedNodes.indexOf(i) > -1\n      });\n    }));\n    if (spec.propSources) _this.nodeSet = (_this$nodeSet = _this.nodeSet).extend.apply(_this$nodeSet, _toConsumableArray(spec.propSources));\n    _this.strict = false;\n    _this.bufferLength = DefaultBufferLength;\n    var tokenArray = decodeArray(spec.tokenData);\n    _this.context = spec.context;\n    _this.specializerSpecs = spec.specialized || [];\n    _this.specialized = new Uint16Array(_this.specializerSpecs.length);\n\n    for (var _i7 = 0; _i7 < _this.specializerSpecs.length; _i7++) {\n      _this.specialized[_i7] = _this.specializerSpecs[_i7].term;\n    }\n\n    _this.specializers = _this.specializerSpecs.map(getSpecializer);\n    _this.states = decodeArray(spec.states, Uint32Array);\n    _this.data = decodeArray(spec.stateData);\n    _this.goto = decodeArray(spec.goto);\n    _this.maxTerm = spec.maxTerm;\n    _this.tokenizers = spec.tokenizers.map(function (value) {\n      return typeof value == \"number\" ? new TokenGroup(tokenArray, value) : value;\n    });\n    _this.topRules = spec.topRules;\n    _this.dialects = spec.dialects || {};\n    _this.dynamicPrecedences = spec.dynamicPrecedences || null;\n    _this.tokenPrecTable = spec.tokenPrec;\n    _this.termNames = spec.termNames || null;\n    _this.maxNode = _this.nodeSet.types.length - 1;\n    _this.dialect = _this.parseDialect();\n    _this.top = _this.topRules[Object.keys(_this.topRules)[0]];\n    return _this;\n  }\n\n  _createClass(LRParser, [{\n    key: \"createParse\",\n    value: function createParse(input, fragments, ranges) {\n      var parse = new Parse(this, input, fragments, ranges);\n\n      var _iterator5 = _createForOfIteratorHelper(this.wrappers),\n          _step5;\n\n      try {\n        for (_iterator5.s(); !(_step5 = _iterator5.n()).done;) {\n          var w = _step5.value;\n          parse = w(parse, input, fragments, ranges);\n        }\n      } catch (err) {\n        _iterator5.e(err);\n      } finally {\n        _iterator5.f();\n      }\n\n      return parse;\n    } /// Get a goto table entry @internal\n\n  }, {\n    key: \"getGoto\",\n    value: function getGoto(state, term) {\n      var loose = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : false;\n      var table = this.goto;\n      if (term >= table[0]) return -1;\n\n      for (var pos = table[term + 1];;) {\n        var groupTag = table[pos++],\n            last = groupTag & 1;\n        var target = table[pos++];\n        if (last && loose) return target;\n\n        for (var end = pos + (groupTag >> 1); pos < end; pos++) {\n          if (table[pos] == state) return target;\n        }\n\n        if (last) return -1;\n      }\n    } /// Check if this state has an action for a given terminal @internal\n\n  }, {\n    key: \"hasAction\",\n    value: function hasAction(state, terminal) {\n      var data = this.data;\n\n      for (var set = 0; set < 2; set++) {\n        for (var i = this.stateSlot(state, set ? 2\n        /* Skip */\n        : 1\n        /* Actions */\n        ), next;; i += 3) {\n          if ((next = data[i]) == 65535\n          /* End */\n          ) {\n            if (data[i + 1] == 1\n            /* Next */\n            ) next = data[i = pair(data, i + 2)];else if (data[i + 1] == 2\n            /* Other */\n            ) return pair(data, i + 2);else break;\n          }\n\n          if (next == terminal || next == 0\n          /* Err */\n          ) return pair(data, i + 1);\n        }\n      }\n\n      return 0;\n    } /// @internal\n\n  }, {\n    key: \"stateSlot\",\n    value: function stateSlot(state, slot) {\n      return this.states[state * 6\n      /* Size */\n      + slot];\n    } /// @internal\n\n  }, {\n    key: \"stateFlag\",\n    value: function stateFlag(state, flag) {\n      return (this.stateSlot(state, 0\n      /* Flags */\n      ) & flag) > 0;\n    } /// @internal\n\n  }, {\n    key: \"validAction\",\n    value: function validAction(state, action) {\n      if (action == this.stateSlot(state, 4\n      /* DefaultReduce */\n      )) return true;\n\n      for (var i = this.stateSlot(state, 1\n      /* Actions */\n      );; i += 3) {\n        if (this.data[i] == 65535\n        /* End */\n        ) {\n          if (this.data[i + 1] == 1\n          /* Next */\n          ) i = pair(this.data, i + 2);else return false;\n        }\n\n        if (action == pair(this.data, i + 1)) return true;\n      }\n    } /// Get the states that can follow this one through shift actions or\n    /// goto jumps. @internal\n\n  }, {\n    key: \"nextStates\",\n    value: function nextStates(state) {\n      var _this2 = this;\n\n      var result = [];\n\n      for (var i = this.stateSlot(state, 1\n      /* Actions */\n      );; i += 3) {\n        if (this.data[i] == 65535\n        /* End */\n        ) {\n          if (this.data[i + 1] == 1\n          /* Next */\n          ) i = pair(this.data, i + 2);else break;\n        }\n\n        if ((this.data[i + 2] & 65536\n        /* ReduceFlag */\n        >> 16) == 0) {\n          (function () {\n            var value = _this2.data[i + 1];\n            if (!result.some(function (v, i) {\n              return i & 1 && v == value;\n            })) result.push(_this2.data[i], value);\n          })();\n        }\n      }\n\n      return result;\n    } /// @internal\n\n  }, {\n    key: \"overrides\",\n    value: function overrides(token, prev) {\n      var iPrev = findOffset(this.data, this.tokenPrecTable, prev);\n      return iPrev < 0 || findOffset(this.data, this.tokenPrecTable, token) < iPrev;\n    } /// Configure the parser. Returns a new parser instance that has the\n    /// given settings modified. Settings not provided in `config` are\n    /// kept from the original parser.\n\n  }, {\n    key: \"configure\",\n    value: function configure(config) {\n      var _this$nodeSet2;\n\n      // Hideous reflection-based kludge to make it easy to create a\n      // slightly modified copy of a parser.\n      var copy = Object.assign(Object.create(LRParser.prototype), this);\n      if (config.props) copy.nodeSet = (_this$nodeSet2 = this.nodeSet).extend.apply(_this$nodeSet2, _toConsumableArray(config.props));\n\n      if (config.top) {\n        var info = this.topRules[config.top];\n        if (!info) throw new RangeError(\"Invalid top rule name \".concat(config.top));\n        copy.top = info;\n      }\n\n      if (config.tokenizers) copy.tokenizers = this.tokenizers.map(function (t) {\n        var found = config.tokenizers.find(function (r) {\n          return r.from == t;\n        });\n        return found ? found.to : t;\n      });\n\n      if (config.specializers) {\n        copy.specializers = this.specializers.slice();\n        copy.specializerSpecs = this.specializerSpecs.map(function (s, i) {\n          var found = config.specializers.find(function (r) {\n            return r.from == s.external;\n          });\n          if (!found) return s;\n          var spec = Object.assign(Object.assign({}, s), {\n            external: found.to\n          });\n          copy.specializers[i] = getSpecializer(spec);\n          return spec;\n        });\n      }\n\n      if (config.contextTracker) copy.context = config.contextTracker;\n      if (config.dialect) copy.dialect = this.parseDialect(config.dialect);\n      if (config.strict != null) copy.strict = config.strict;\n      if (config.wrap) copy.wrappers = copy.wrappers.concat(config.wrap);\n      if (config.bufferLength != null) copy.bufferLength = config.bufferLength;\n      return copy;\n    } /// Tells you whether any [parse wrappers](#lr.ParserConfig.wrap)\n    /// are registered for this parser.\n\n  }, {\n    key: \"hasWrappers\",\n    value: function hasWrappers() {\n      return this.wrappers.length > 0;\n    } /// Returns the name associated with a given term. This will only\n    /// work for all terms when the parser was generated with the\n    /// `--names` option. By default, only the names of tagged terms are\n    /// stored.\n\n  }, {\n    key: \"getName\",\n    value: function getName(term) {\n      return this.termNames ? this.termNames[term] : String(term <= this.maxNode && this.nodeSet.types[term].name || term);\n    } /// The eof term id is always allocated directly after the node\n    /// types. @internal\n\n  }, {\n    key: \"dynamicPrecedence\",\n    /// @internal\n    value: function dynamicPrecedence(term) {\n      var prec = this.dynamicPrecedences;\n      return prec == null ? 0 : prec[term] || 0;\n    } /// @internal\n\n  }, {\n    key: \"parseDialect\",\n    value: function parseDialect(dialect) {\n      var values = Object.keys(this.dialects),\n          flags = values.map(function () {\n        return false;\n      });\n\n      if (dialect) {\n        var _iterator6 = _createForOfIteratorHelper(dialect.split(\" \")),\n            _step6;\n\n        try {\n          for (_iterator6.s(); !(_step6 = _iterator6.n()).done;) {\n            var part = _step6.value;\n\n            var _id = values.indexOf(part);\n\n            if (_id >= 0) flags[_id] = true;\n          }\n        } catch (err) {\n          _iterator6.e(err);\n        } finally {\n          _iterator6.f();\n        }\n      }\n\n      var disabled = null;\n\n      for (var i = 0; i < values.length; i++) {\n        if (!flags[i]) {\n          for (var j = this.dialects[values[i]], _id2; (_id2 = this.data[j++]) != 65535\n          /* End */\n          ;) {\n            (disabled || (disabled = new Uint8Array(this.maxTerm + 1)))[_id2] = 1;\n          }\n        }\n      }\n\n      return new Dialect(dialect, flags, disabled);\n    } /// Used by the output of the parser generator. Not available to\n    /// user code.\n\n  }, {\n    key: \"eofTerm\",\n    get: function get() {\n      return this.maxNode + 1;\n    } /// The type of top node produced by the parser.\n\n  }, {\n    key: \"topNode\",\n    get: function get() {\n      return this.nodeSet.types[this.top[1]];\n    }\n  }], [{\n    key: \"deserialize\",\n    value: function deserialize(spec) {\n      return new LRParser(spec);\n    }\n  }]);\n\n  return LRParser;\n}(Parser);\n\nfunction pair(data, off) {\n  return data[off] | data[off + 1] << 16;\n}\n\nfunction findOffset(data, start, term) {\n  for (var i = start, next; (next = data[i]) != 65535\n  /* End */\n  ; i++) {\n    if (next == term) return i - start;\n  }\n\n  return -1;\n}\n\nfunction findFinished(stacks) {\n  var best = null;\n\n  var _iterator7 = _createForOfIteratorHelper(stacks),\n      _step7;\n\n  try {\n    for (_iterator7.s(); !(_step7 = _iterator7.n()).done;) {\n      var _stack4 = _step7.value;\n      var stopped = _stack4.p.stoppedAt;\n      if ((_stack4.pos == _stack4.p.stream.end || stopped != null && _stack4.pos > stopped) && _stack4.p.parser.stateFlag(_stack4.state, 2\n      /* Accepting */\n      ) && (!best || best.score < _stack4.score)) best = _stack4;\n    }\n  } catch (err) {\n    _iterator7.e(err);\n  } finally {\n    _iterator7.f();\n  }\n\n  return best;\n}\n\nfunction getSpecializer(spec) {\n  if (spec.external) {\n    var mask = spec.extend ? 1\n    /* Extend */\n    : 0\n    /* Specialize */\n    ;\n    return function (value, stack) {\n      return spec.external(value, stack) << 1 | mask;\n    };\n  }\n\n  return spec.get;\n}\n\nexport { ContextTracker, ExternalTokenizer, InputStream, LRParser, Stack };","map":null,"metadata":{},"sourceType":"module"}